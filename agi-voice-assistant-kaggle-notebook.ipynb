{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6d84d50",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-18T14:16:31.089242Z",
     "iopub.status.busy": "2025-07-18T14:16:31.088959Z",
     "iopub.status.idle": "2025-07-18T14:16:32.950339Z",
     "shell.execute_reply": "2025-07-18T14:16:32.949292Z"
    },
    "papermill": {
     "duration": 1.866426,
     "end_time": "2025-07-18T14:16:32.952130",
     "exception": false,
     "start_time": "2025-07-18T14:16:31.085704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8452fa26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-18T14:16:32.957143Z",
     "iopub.status.busy": "2025-07-18T14:16:32.956750Z",
     "iopub.status.idle": "2025-07-18T14:16:42.535022Z",
     "shell.execute_reply": "2025-07-18T14:16:42.533810Z"
    },
    "papermill": {
     "duration": 9.582292,
     "end_time": "2025-07-18T14:16:42.536366",
     "exception": true,
     "start_time": "2025-07-18T14:16:32.954074",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.91.0)\r\n",
      "Collecting elevenlabs\r\n",
      "  Downloading elevenlabs-2.7.1-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Collecting python-dotenv\r\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\r\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\r\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\r\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.11/dist-packages (from elevenlabs) (2.33.2)\r\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from elevenlabs) (2.32.4)\r\n",
      "Requirement already satisfied: websockets>=11.0 in /usr/local/lib/python3.11/dist-packages (from elevenlabs) (15.0.1)\r\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\r\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\r\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\r\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->elevenlabs) (3.4.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->elevenlabs) (2.5.0)\r\n",
      "Downloading elevenlabs-2.7.1-py3-none-any.whl (760 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.8/760.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\r\n",
      "Installing collected packages: python-dotenv, elevenlabs\r\n",
      "Successfully installed elevenlabs-2.7.1 python-dotenv-1.1.1\r\n",
      "\n",
      "User Query: What is the future of AGI voice assistants?\n"
     ]
    },
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/2367254490.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nUser Query: {user_input}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mresponse_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_with_gpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GPT-4o Response:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13/2367254490.py\u001b[0m in \u001b[0;36mchat_with_gpt\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Function to chat with GPT-4o\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchat_with_gpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     response = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4o\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/lib/_old_api.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAPIRemovedInV1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "# AGI Voice Assistant - Kaggle Notebook Version (Enhanced)\n",
    "\n",
    "# Install required packages\n",
    "!pip install openai elevenlabs python-dotenv\n",
    "\n",
    "import os\n",
    "import openai\n",
    "from elevenlabs import ElevenLabs, VoiceSettings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API keys from environment variables in .env file\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "elevenlabs_api_key = os.getenv(\"ELEVENLABS_API_KEY\")\n",
    "\n",
    "# Initialize ElevenLabs client\n",
    "client = ElevenLabs(api_key=elevenlabs_api_key)\n",
    "\n",
    "# Function to chat with GPT-4o\n",
    "def chat_with_gpt(prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    reply = response.choices[0].message['content']\n",
    "    return reply\n",
    "\n",
    "# Function to generate voice from text using ElevenLabs\n",
    "def generate_voice(text):\n",
    "    audio = client.generate(\n",
    "        text=text,\n",
    "        voice=\"Rachel\",\n",
    "        model=\"eleven_multilingual_v2\",\n",
    "        voice_settings=VoiceSettings(\n",
    "            stability=0.5,\n",
    "            similarity_boost=0.5\n",
    "        )\n",
    "    )\n",
    "    with open(\"response_audio.mp3\", \"wb\") as f:\n",
    "        f.write(audio)\n",
    "    print(\"Voice response saved as response_audio.mp3\")\n",
    "\n",
    "# ---- Example Interaction ----\n",
    "queries = [\n",
    "    \"What is the future of AGI voice assistants?\",\n",
    "    \"Explain quantum computing in simple terms.\",\n",
    "    \"What are the latest trends in AI healthcare?\"\n",
    "]\n",
    "\n",
    "for user_input in queries:\n",
    "    print(f\"\\nUser Query: {user_input}\")\n",
    "\n",
    "    response_text = chat_with_gpt(user_input)\n",
    "    print(\"GPT-4o Response:\", response_text)\n",
    "\n",
    "    speak = \"no\"  # Change to 'yes' to enable voice output\n",
    "    if speak.lower() == \"yes\":\n",
    "        generate_voice(response_text)\n",
    "\n",
    "# ----- Notes -----\n",
    "# Ensure you have a `.env` file in the environment with:\n",
    "# OPENAI_API_KEY=your_openai_api_key\n",
    "# ELEVENLABS_API_KEY=your_elevenlabs_api_key\n",
    "\n",
    "# This notebook runs multiple predefined queries sequentially.\n",
    "# Change `speak = \"yes\"` if you want audio output for each response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3db4919",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install openai elevenlabs python-dotenv\n",
    "\n",
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from elevenlabs import ElevenLabs, VoiceSettings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API keys from environment variables in .env file\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "elevenlabs_api_key = os.getenv(\"ELEVENLABS_API_KEY\")\n",
    "\n",
    "# Initialize OpenAI and ElevenLabs clients\n",
    "client_ai = OpenAI(api_key=openai_api_key)\n",
    "client_voice = ElevenLabs(api_key=elevenlabs_api_key)\n",
    "\n",
    "# Function to chat with GPT-4o (new SDK)\n",
    "def chat_with_gpt(prompt):\n",
    "    response = client_ai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    reply = response.choices[0].message.content\n",
    "    return reply\n",
    "\n",
    "# Function to generate voice from text using ElevenLabs\n",
    "def generate_voice(text):\n",
    "    audio = client_voice.generate(\n",
    "        text=text,\n",
    "        voice=\"Rachel\",\n",
    "        model=\"eleven_multilingual_v2\",\n",
    "        voice_settings=VoiceSettings(\n",
    "            stability=0.5,\n",
    "            similarity_boost=0.5\n",
    "        )\n",
    "    )\n",
    "    with open(\"response_audio.mp3\", \"wb\") as f:\n",
    "        f.write(audio)\n",
    "    print(\"Voice response saved as response_audio.mp3\")\n",
    "\n",
    "# Example Interaction\n",
    "queries = [\n",
    "    \"What is the future of AGI voice assistants?\",\n",
    "    \"Explain quantum computing in simple terms.\",\n",
    "    \"What are the latest trends in AI healthcare?\"\n",
    "]\n",
    "\n",
    "speak = \"no\"  # change to \"yes\" to enable voice\n",
    "\n",
    "for user_input in queries:\n",
    "    print(f\"\\nUser Query: {user_input}\")\n",
    "    response_text = chat_with_gpt(user_input)\n",
    "    print(\"GPT-4o Response:\", response_text)\n",
    "\n",
    "    if speak.lower() == \"yes\":\n",
    "        generate_voice(response_text)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.113026,
   "end_time": "2025-07-18T14:16:43.358980",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-18T14:16:26.245954",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
