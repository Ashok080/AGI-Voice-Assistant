{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72d37507",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-16T06:29:36.768101Z",
     "iopub.status.busy": "2025-07-16T06:29:36.767191Z",
     "iopub.status.idle": "2025-07-16T06:29:38.558545Z",
     "shell.execute_reply": "2025-07-16T06:29:38.557621Z"
    },
    "papermill": {
     "duration": 1.796489,
     "end_time": "2025-07-16T06:29:38.560158",
     "exception": false,
     "start_time": "2025-07-16T06:29:36.763669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a28459f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T06:29:38.564634Z",
     "iopub.status.busy": "2025-07-16T06:29:38.564239Z",
     "iopub.status.idle": "2025-07-16T06:29:38.575240Z",
     "shell.execute_reply": "2025-07-16T06:29:38.574104Z"
    },
    "papermill": {
     "duration": 0.014746,
     "end_time": "2025-07-16T06:29:38.576614",
     "exception": true,
     "start_time": "2025-07-16T06:29:38.561868",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character 'â€™' (U+2019) (3315430429.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_13/3315430429.py\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    - Enhance the AGI agentâ€™s reasoning with relevant context\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character 'â€™' (U+2019)\n"
     ]
    }
   ],
   "source": [
    "# ðŸ”Ž AGI Voice Agent - RAG Pipeline Build (Notebook 11)\n",
    "\n",
    "### Objective:\n",
    "Implement Retrieval-Augmented Generation (RAG) to:\n",
    "- Retrieve knowledge from the 73 datasets\n",
    "- Enhance the AGI agentâ€™s reasoning with relevant context\n",
    "- Generate more accurate and informed responses\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ðŸ“Œ 1. Install Required Libraries\n",
    "\n",
    "!pip install langchain sentence-transformers faiss-cpu transformers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ðŸ“Œ 2. Load Libraries\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ðŸ“Œ 3. Prepare Embeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Example dataset\n",
    "df = pd.read_parquet('processed/ai_reasoning_features.parquet')\n",
    "documents = df['question'].fillna('').tolist()\n",
    "\n",
    "# Create embeddings\n",
    "doc_embeddings = embedding_model.embed_documents(documents)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ðŸ“Œ 4. Create FAISS Vector Store\n",
    "\n",
    "db = FAISS.from_texts(documents, embedding_model)\n",
    "db.save_local(\"vectorstore/agi_voice_agent_faiss\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ðŸ“Œ 5. Load Vector Store for Retrieval\n",
    "\n",
    "db = FAISS.load_local(\"vectorstore/agi_voice_agent_faiss\", embedding_model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ðŸ“Œ 6. Retrieve Relevant Context\n",
    "\n",
    "def retrieve_context(query, k=3):\n",
    "    results = db.similarity_search(query, k=k)\n",
    "    return \"\\n\".join([r.page_content for r in results])\n",
    "\n",
    "query = \"Explain the theory of consciousness\"\n",
    "context = retrieve_context(query)\n",
    "print(\"Retrieved Context:\\n\", context)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ðŸ“Œ 7. Connect to Language Model for Generation\n",
    "\n",
    "generator = pipeline('text-generation', model='gpt2', max_length=200)\n",
    "llm = HuggingFacePipeline(pipeline=generator)\n",
    "\n",
    "def generate_rag_response(query):\n",
    "    context = retrieve_context(query)\n",
    "    prompt = f\"Context:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    response = llm(prompt)\n",
    "    return response[0]['generated_text']\n",
    "\n",
    "# Example\n",
    "response = generate_rag_response(query)\n",
    "print(\"RAG Response:\\n\", response)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.881719,
   "end_time": "2025-07-16T06:29:39.100532",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-16T06:29:32.218813",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
